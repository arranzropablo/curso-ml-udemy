{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de la regresión logística con el método de la máxima verosimilitud\n",
    "\n",
    "## Definir la función de entorno $L(\\beta)$\n",
    "\n",
    "Recordamos que ya no hay $\\alpha$, sino $\\beta_0$\n",
    "\n",
    "$$L(\\alpha,\\beta) = \\prod^n_{i=1} P_i^{y_i} \\cdot (1 - P_i)^{1 - y_i}$$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(y, p):\n",
    "    totalprod = 1\n",
    "    for i in range(len(y)):\n",
    "        row = np.where(y[i] == 1, p[i], 1 - p[i])\n",
    "        totalprod = totalprod * row\n",
    "    return totalprod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular las probabilidades para cada observación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las probabilidades se calculan con la función sigmoide:\n",
    "\n",
    "$$P(x_i) = \\frac{1}{1 + e^{-\\beta x_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probs(beta, X):\n",
    "    import numpy as np\n",
    "    return 1/(1 + np.exp(-np.transpose(np.matrix(beta))*np.transpose(np.matrix(X))))\n",
    "#en teoría devuelve las probabilidades en 1xn\n",
    "#seguramente no funcione y haya que pasar beta y X a matrices o algo así... o usar np.prod() para hacer el prod matricial..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la matriz diagonal W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ W = diag(P_i \\cdot (1 - P_i))^n_{i=1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def diagw(p):\n",
    "    import numpy as np\n",
    "    w = np.zeros(len(p) * len(p)).reshape(len(p), len(p))\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        w[i,i] = (p[i] * np.transpose(np.matrix(1 - p[i]))).astype(float)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la función logística\n",
    "\n",
    "E implementar también el método de Newton-Raphson.<br>\n",
    "$$ \\beta_{n+1} = \\beta_n - \\frac{f(\\beta_n)}{f'(\\beta_n)} $$\n",
    "\n",
    "$$f(\\beta) = X(Y - P)$$\n",
    "$$f'(\\beta) = X\\omega X^t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(X_original, y, limit):\n",
    "    import numpy as np\n",
    "    from numpy import linalg\n",
    "    \n",
    "    nrows = np.shape(X_original)[0]\n",
    "    ncols = np.shape(X_original)[1] + 1\n",
    "    \n",
    "    bias = np.ones(nrows).reshape(nrows, 1)\n",
    "    X = np.append(bias, X_original, axis = 1)\n",
    "\n",
    "    #Inicializamos las betas a 0\n",
    "    beta = np.zeros(ncols).reshape(ncols, 1)\n",
    "    #En este array iremos guardando las diferencias entre cada iteración para comprobar cuando parar\n",
    "    beta_dif = np.array(range(ncols)).reshape(ncols, 1)\n",
    "    \n",
    "    #Paramos cuando el cuadrado de las diferencias sea menor que el limite establecido\n",
    "    while(sum(beta_dif * beta_dif) > limit):\n",
    "        \n",
    "        p = np.transpose(np.matrix(probs(beta, X)))\n",
    "        w = diagw(p)\n",
    "\n",
    "        f_beta = np.transpose(np.matrix(X)) * (y - p)\n",
    "        derivate_f_beta = np.transpose(np.matrix(X)) * w * X\n",
    "\n",
    "        beta_dif = np.array(linalg.inv(derivate_f_beta) * f_beta)\n",
    "        beta = beta + beta_dif\n",
    "        \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando nuestra implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69557172],\n",
       "       [ 0.66220827]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nrows = 10\n",
    "\n",
    "X = np.array(range(nrows)).reshape(nrows, 1)\n",
    "y = np.array([0, 0, 0, 0, 1, 0, 1, 0, 1, 1]).reshape(nrows, 1)\n",
    "\n",
    "beta = logistic(X, y, 0.00001)\n",
    "\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01343191]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Esto no entiendo muy bien que implica, la función de coste?? Nos sale diferente a él y a mi\n",
    "#Sin embargo las betas me salen iguales\n",
    "likelihood(y, probs(beta, np.append(np.ones(nrows).reshape(nrows, 1), X, axis=1)).reshape(nrows, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando la diferencia con el paquete de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.431012\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Para llamar a la regresión logística de statsmodels hay que añadir antes el bias\n",
    "model = sm.Logit(y, np.append(np.ones(nrows).reshape(nrows, 1), X, axis=1))\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 15 Jun 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.3596</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:57:50</td>     <th>  Log-Likelihood:    </th> <td> -4.3101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -6.7301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.02781</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.6956</td> <td>    2.289</td> <td>   -1.615</td> <td> 0.106</td> <td>   -8.182     0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6622</td> <td>    0.400</td> <td>    1.655</td> <td> 0.098</td> <td>   -0.122     1.446</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   10\n",
       "Model:                          Logit   Df Residuals:                        8\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Fri, 15 Jun 2018   Pseudo R-squ.:                  0.3596\n",
       "Time:                        17:57:50   Log-Likelihood:                -4.3101\n",
       "converged:                       True   LL-Null:                       -6.7301\n",
       "                                        LLR p-value:                   0.02781\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.6956      2.289     -1.615      0.106        -8.182     0.791\n",
       "x1             0.6622      0.400      1.655      0.098        -0.122     1.446\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
